# üèÄ Preditor de Arremessos de Kobe Bryant üèÄ

**Alan Alonso**
---

## Estrutura do Projeto (TDSP)

```bash
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ 01_raw/
‚îÇ   ‚îú‚îÄ‚îÄ 02_intermediate/
‚îÇ   ‚îú‚îÄ‚îÄ 03_primary/
‚îÇ   ‚îú‚îÄ‚îÄ 05_model_input/
‚îÇ   ‚îú‚îÄ‚îÄ 06_models/
‚îÇ   ‚îú‚îÄ‚îÄ 07_model_output/
‚îÇ   ‚îî‚îÄ‚îÄ 08_reporting/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ docs/source
‚îú‚îÄ‚îÄ src/
‚îú‚îÄ‚îÄ mlruns/
‚îú‚îÄ‚îÄ streamlit/
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile / docker-compose
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ aplicacao.py
```

---

## Introdu√ß√£o

Este projeto busca criar um preditor de acertos de arremessos de Black Mamba, tamb√©m conhecido como Kobe Bryant! Baseando-se em dados de contexto da jogada. Com t√©cnicas de engenharia de machine learning para processar, treinar, comparar e implantar modelos, visando apoiar melhorar a qualidade desta previs√£o.

---

## Diagrama de Pipeline

![Diagrama](/docs/source/diagrama.png)
---

## Ferramentas Utilizadas

| Ferramenta       | Papel no Projeto                                                                 |
| ---------------- | -------------------------------------------------------------------------------- |
| **MLflow**       | Registro e acompanhamento dos experimentos, m√©tricas e modelos; versionamento    |
| **PyCaret**      | Cria√ß√£o automatizada de pipelines de machine learning (setup, tuning, avalia√ß√£o) |
| **Scikit-learn** | Execu√ß√£o dos algoritmos (regress√£o log√≠stica, √°rvore), m√©tricas personalizadas   |
| **Streamlit**    | Interface visual para simular arremessos e monitorar o modelo em tempo real      |


---

## Artefatos do Projeto

| Artefato                                 | Descri√ß√£o                           |
| ---------------------------------------- | ----------------------------------- |
| `aplicacao.ipynb`                        | Notebook que cont√™m os pipelines    |
| `dataset_kobe_dev.parquet`               | Dados originais de desenvolvimento  |
| `dataset_kobe_prod.parquet`              | Dados originais de produ√ß√£o         |
| `base_filtered.parquet`                  | Dados tratados para treino / teste  |
| `base_train.parquet`                     | Dados processados para treino       |
| `base_test.parquet`                      | Dados processados para teste        |
| `model_regression_logistic_dev.pkl`      | Modelo de treinamento de reg-log    |
| `model_decision_tree_dev.pkl`            | Modelo de treinamento de dt         |
| `robust_scaler.pkl`                      | Modelo de normaliza√ß√£o dos dados    |
| `predictions_prod.parquet`               | Previs√µes geradas na produ√ß√£o       |
| `streamlit/app.py`                       | Interface interativa                |

---

## Processamento de Dados

- Dados de entrada: `/data/raw/dataset_kobe_dev.parquet`
    - Base de dados de desenvolvimento, enquanto a `/data/raw/dataset_kobe_prod.parquet` √© utilizada para a etapa de aplica√ß√£o do modelo treinado escolhido
- Colunas utilizadas: `lat`, `lon`, `minutes_remaining`, `period`, `playoffs`, `shot_distance`
    - `lat` e `lon`: Latitude e longitude da quadra, ambos do tipo float.
    - `minutes_remaining`, `period`, `playoffs`: Tempo que falta no per√≠odo, qual per√≠odo estamos, e se √© ou n√£o play-off, todos do tipo inteiro.
    - `shot_distance`: Dist√¢ncia para a c√™sta, tamb√©m um n√∫mero inteiro.
- Remo√ß√£o de linhas com nulos
- Normaliza√ß√£o robusta dos dados, para lidar melhor com outliers e ter dados adequados para ambos os modelos de teste
- Dados salvos em `/data/03_primary/` com dimens√£o (20285, 7)
- Split estratificado 80/20 gerando arquivos e salvando em `/data/05_model_input/`
    - Train shape: (16228, 6)
    - Test shape: (4057, 6)


> **Como o split afeta o modelo?**\
> O split busca evitar que haja overfitting e tamb√©m garante generaliza√ß√£o, impedindo que um modelo funcione bem apenas para um grupo espec√≠fico de dados dentro do universo de amostragem. A estratifica√ß√£o preserva a distribui√ß√£o das classes. Para minimizar vi√©s, √© importante normaliza√ß√£o, balanceamento e valida√ß√£o cruzada.

---

## Treinamento e Sele√ß√£o de Modelos

- **Modelos testados (metricas: F1 Score e Log Loss):**

  - Regress√£o Log√≠stica (PyCaret)
    - üìà F1 Score: 0.5732
    - üìâ Log Loss: 0.7131
  - √Årvore de Decis√£o (PyCaret)
    - üìà F1 Score: 0.5478
    - üìâ Log Loss: 15.3255

- Registro completo com `mlflow`

> **Modelo escolhido:** *[Regress√£o Log√≠stica]*\
> **Justificativa:** *[Melhor valor de F1 score e de Log loss]*
> Nota-se que o valor de F1 score, apesar de n√£o ser muito alto, indica que o modelo escolhido √© melhor do que uma escolha aleat√≥ria. No contexto de um esporte com tantos arremessos (um universo grande de dados), mesmo valores longe do ideal podem ser suficiente para garantir a utilidade do modelo. Em especial, nota-se que a √°rvore de decis√£o √© menos recomendada por um valor extremamente alto de Log loss, o que condiz com um modelo que tem tend√™ncia a gerar probabilidades muito extremas, em compara√ß√£o com um modelo probabilistico como a regress√£o logistica. Especialmente em modelos que tenham alto risco em caso de erro (n√£o √© o caso deste), √© recomendado evitar.

---

## Aplica√ß√£o em Produ√ß√£o

- Dados de produ√ß√£o: `/data/raw/dataset_kobe_prod.parquet`
- Previs√µes realizadas com modelo final
- Resultados salvos em `/data/07_model_output/`
- Nova run registrada como `PipelineAplicacao`

**M√©tricas em produ√ß√£o:**

- F1 Score: *[0]*
- Log Loss: *[24.1700]*

> **Mudan√ßas detectadas:** *[Distribui√ß√£o de uma das vari√°veis]*\
> **Modelo manteve performance?** *[N√£o]*
> Apesar de estranho, era esperado este tipo de comportamento tendo em vista que estes arremessos aparentam ser exclusivamentes para uma "cesta de 3", dessa forma um modelo treinado para uma distribui√ß√£o diferente n√£o pode ser aplicado para estes dados.

![Arremessos do treinamento do modelo](/docs/source/arremessos_dev.png)
![Arremessos da aplica√ß√£o do modelo](/docs/source/arremessos_prod.png)

---

## Monitoramento e Retreinamento

- **Com resposta:** Em um cen√°rio com a vari√°vel resposta podemos utilizar os mesmos par√¢metros como F1 Score e Log Loss para avaliar a sua cont√≠nua aplicabilidade. Al√©m disso, curva ROC, e outras figuras de m√©rito como acur√°cia e recall podem ser par√¢metros auxiliares
- **Sem resposta:** Sem as respostas √© interessante observar a varia√ß√£o da distribui√ß√£o das vari√°veis de entrada, comparando com a m√©dia e desvio padr√£o dos dados com resposta conhecida. Caso haja um desbalanceamento, um novo treinamento pode ser necess√°rio.

**Estrat√©gias:**

- **Reativa:** Ao detectar uma queda de performance o modelo deve ser retreinado. Seja por uma queda nos par√¢metros case tenhamos a resposta, seja com uma mudan√ßa drastica na destribui√ß√£o das vari√°veis de entrada. √â um modelo de corre√ß√£o mais simples de aplicar mas pode ocorrer com uma certa defasagem ap√≥s o momendo de necessidade de mudan√ßa do modelo.
- **Preditiva:** Possui uma periodicidade com base na an√°lise hist√≥rica de quando o modelo pode se deteriorar. Apesar de ser menor eficiente computacionalmente, pode melhorar a estabilidade do modelo .

---

## Dashboard Streamlit

- Local: `streamlit/app.py`
- Permite simula√ß√£o de arremessos com feedback instant√¢neo de probabilidade

![Streamlit](/docs/source/streamlit.png)

---

## Mlflow

- Registro dos par√¢metros das runs

![mlflow](/docs/source/mlflow.png)

---

## Como Executar

### Instalar depend√™ncias:

```bash
pip install -r requirements.txt
```

### Rodar aplica√ß√£o de infer√™ncia:

```bash
python aplicacao.py
```

### Iniciar o painel de monitoramento:

```bash
cd /workspaces/kobe-pd/streamlit
streamlit run streamlit/streamlit_app.py
```

### Iniciar o MLflow (opcional):

```bash
mlflow ui --backend-store-uri file:../mlruns
```

---

## Link do Reposit√≥rio

[https://github.com/AlansAlonso/eng-ML](https://github.com/AlansAlonso/eng-ML)

## Link da Aplicacao

[https://github.com/AlansAlonso/eng-ML/blob/main/aplicacao.ipynb](https://github.com/AlansAlonso/eng-ML/blob/main/aplicacao.ipynb)

---

## Aviso ao professor
> Inicialmente este projeto foi feito com o dev container providenciado, utilizando kedro, os requirements_antigo s√£o os originais. Contudo, devido a problemas no versionamento de kedro e mlflow, precisei realiz√°-lo de uma forma que eu estava mais familiar, atrav√©s de notebooks, buscando emular e evid√™nciar em cada trecho as "pipelines" que estariam ocorrendo. No mais, aproveitei as pastas criadas pelo kedro dentro das minhas habilidades para organizar o trabalho da melhor forma poss√≠vel.
